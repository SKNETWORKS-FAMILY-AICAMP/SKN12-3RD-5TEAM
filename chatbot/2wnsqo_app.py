# streamlit run app.py
import os
import faiss
import numpy as np
import streamlit as st
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë„ˆì˜ í‚¤ë¡œ ëŒ€ì²´)
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# ---- í•¨ìˆ˜ ì •ì˜ ----

@st.cache_resource
def load_embedding_model():
    return SentenceTransformer("jhgan/ko-sroberta-multitask")

@st.cache_resource
def load_faiss_index(index_path: str):
    return faiss.read_index(index_path)

@st.cache_data
def load_chunks(chunk_path: str):
    with open(chunk_path, "r", encoding="utf-8") as f:
        return [c.strip() for c in f.read().split("\n\n") if c.strip()]

def search_similar_chunks(question: str, index, chunks, model, top_k=3):
    embedding = model.encode([question])
    _, indices = index.search(np.array(embedding).astype("float32"), top_k)
    return [chunks[i] for i in indices[0]]

def build_rag_chain():
    prompt = PromptTemplate.from_template(
        "ë‹¹ì‹ ì€ ì˜í•™ì „ê³µì„ í•˜ì—¬ ì €í¬ì˜ ì§ˆë¬¸ì— ëŒ€ë‹µì„ ì˜ í•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤"
        "ë§Œì•½ ì§„ë£Œí˜¹ì€ ì•½, ì˜í•™ê³¼ ê´€ë ¨ì´ ì—†ëŠ” ì§ˆë¬¸ì´ë©´ ì§ˆë¬¸ì´ ì£¼ì œì™€ ë‹¤ë¥´ë‹¤ê³  í•˜ë©´ ë©ë‹ˆë‹¤"
        "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ì°¸ê³  ë¬¸ì„œì…ë‹ˆë‹¤:\n\n"
        "{context}\n\n"
        "---\n\n"
        "ì§ˆë¬¸: {question}\n"
        "ë‹µë³€:"
    )
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    return prompt | llm | StrOutputParser()

def get_rag_answer(question: str, index, chunks, model, rag_chain):
    top_chunks = search_similar_chunks(question, index, chunks, model)
    context = "\n".join(top_chunks)
    return rag_chain.invoke({"context": context, "question": question})

# ---- Streamlit UI ----

st.set_page_config(page_title="ğŸ§  ê±´ê°• RAG ì±—ë´‡", page_icon="ğŸ’¬")
st.title("ğŸ’¬ ê±´ê°• ì§ˆì˜ì‘ë‹µ RAG ì±—ë´‡")

# ëª¨ë¸ & ë°ì´í„° ë¡œë“œ
embed_model = load_embedding_model()
index = load_faiss_index("./embedding/QA_random_pair_part2_index1.index")
chunks = load_chunks("./embedding/QA_random_pair_part2_chunks1.txt")
rag_chain = build_rag_chain()

# ì‚¬ìš©ì ì…ë ¥
question = st.text_input("â“ ê¶ê¸ˆí•œ ê±´ê°• ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="input")

if st.button("ì§ˆë¬¸í•˜ê¸°") and question.strip():
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        answer = get_rag_answer(question, index, chunks, embed_model, rag_chain)
    st.markdown("### ğŸ“Œ ë‹µë³€:")
    st.success(answer)
