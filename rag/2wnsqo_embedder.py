import os
import torch
from sentence_transformers import SentenceTransformer
import faiss

def load_chunks(file_path: str) -> list:
    """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¤„ ë‹¨ìœ„ë¡œ ì²­í¬ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    with open(file_path, "r", encoding="utf-8-sig") as f:
        chunks = [line.strip() for line in f if line.strip()]
    print(f"ğŸ“„ ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¥¼ ë¶ˆëŸ¬ì™”ì–´.")
    return chunks

def get_embedding_model(model_name: str = "jhgan/ko-sroberta-multitask"):
    """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ ì‚¬ìš©í•˜ëŠ” ë””ë°”ì´ìŠ¤: {device}")
    return SentenceTransformer(model_name, device=device)

def create_faiss_index(embeddings):
    """FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë²¡í„°ë¥¼ ì¶”ê°€"""
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)
    print(f"âœ… FAISS ì¸ë±ìŠ¤ì— {len(embeddings)}ê°œì˜ ë²¡í„°ê°€ ì¶”ê°€ë˜ì—ˆì–´.")
    return index

def save_index_and_chunks(index, index_path: str, chunks: list, chunk_path: str):
    """FAISS ì¸ë±ìŠ¤ì™€ ì²­í¬ë¥¼ ì €ì¥"""
    faiss.write_index(index, index_path)
    with open(chunk_path, "w", encoding="utf-8") as f:
        for chunk in chunks:
            f.write(chunk + "\n\n")
    print(f"ğŸ’¾ ì¸ë±ìŠ¤ ì €ì¥: {index_path}")
    print(f"ğŸ’¾ ì²­í¬ ì €ì¥: {chunk_path}")

def embed_and_save_faiss(file_path: str, index_path: str, chunk_path: str):
    """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰: í…ìŠ¤íŠ¸ â†’ ì„ë² ë”© â†’ FAISS ì¸ë±ìŠ¤ ìƒì„± â†’ ì €ì¥"""
    chunks = load_chunks(file_path)
    model = get_embedding_model()
    print(f"ğŸ§  ì„ë² ë”© ì‹œì‘...")
    embeddings = model.encode(chunks, batch_size=64, show_progress_bar=True)
    index = create_faiss_index(embeddings)
    save_index_and_chunks(index, index_path, chunks, chunk_path)
    print("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆì–´!")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    embed_and_save_faiss(
        file_path="./QA_random_pair_part2_preprocessed.txt",
        index_path="./embedding/QA_random_pair_part2_index1.index",
        chunk_path="./embedding/QA_random_pair_part2_chunks1.txt"
    )
