# ! pip install langchain langchain-community openai sentence-transformers faiss-cpu
import os
import faiss
import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# ì²­í¬ ë¶ˆëŸ¬ì˜¤ê¸°
def load_chunks(chunk_path: str):
    with open(chunk_path, "r", encoding="utf-8") as f:
        return [c.strip() for c in f.read().split("\n\n") if c.strip()]

# FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
def load_faiss_index(index_path: str):
    return faiss.read_index(index_path)

# ìœ ì‚¬í•œ ì²­í¬ ì°¾ê¸°
def search_faiss_index(question: str, index, chunks, model, top_k=3):
    embedding = model.encode([question])
    _, indices = index.search(np.array(embedding).astype("float32"), top_k)
    return [chunks[i] for i in indices[0]]

# RAG ì²´ì¸ ë§Œë“¤ê¸°
def build_rag_chain():
    prompt = PromptTemplate.from_template(
        "ë‹¹ì‹ ì€ í™˜ìë“¤ì—ê²Œ ì§ˆë³‘ ë° ì•½ì— ëŒ€í•´ ì˜ ì„¤ëª…í•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤ë‹¤"
        "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ì°¸ê³  ë¬¸ì„œì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ ëŒ€ë‹µí•´ì£¼ì„¸ìš”:\n\n"
        "{context}\n\n"
        "---\n\n"
        "ì§ˆë¬¸: {question}\n"
        "ë‹µë³€:"
    )
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    return prompt | llm | StrOutputParser()

# ìµœì¢… RAG ì‘ë‹µ ìƒì„±
def rag_answer(question: str, index, chunks, model, rag_chain):
    top_chunks = search_faiss_index(question, index, chunks, model)
    context = "\n".join(top_chunks)
    return rag_chain.invoke({"context": context, "question": question})

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
    load_dotenv()
    openai_key = os.getenv("OPENAI_API_KEY")

    index = load_faiss_index("./embedding/QA_random_pair_part2_index1.index")
    chunks = load_chunks("./embedding/QA_random_pair_part2_chunks1.txt")
    model = SentenceTransformer("jhgan/ko-sroberta-multitask")
    rag_chain = build_rag_chain()

    # ì˜ˆì‹œ ì§ˆë¬¸
    question = "ê³ ë§‰ì—¼ì—ëŠ” ì–´ë–¤ ì•½ë¬¼ì´ ì‚¬ìš©ë˜ë‚˜ìš”?"
    answer = rag_answer(question, index, chunks, model, rag_chain)

    print("ğŸ’¬ ë‹µë³€:", answer)


