{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6199087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025330d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_all_jsons_from_relative_path(relative_dir_path, max_files=None):\n",
    "    base_dir = Path.cwd()\n",
    "    target_dir = base_dir / relative_dir_path\n",
    "\n",
    "    if not target_dir.exists():\n",
    "        raise FileNotFoundError(f\"디렉토리가 존재하지 않습니다: {target_dir}\")\n",
    "\n",
    "    json_files = list(target_dir.rglob(\"*.json\"))\n",
    "    if max_files is not None:\n",
    "        json_files = json_files[:max_files]\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for json_file in tqdm(json_files, desc=\"JSON 파일 읽는 중\", unit=\"file\"):\n",
    "        try:\n",
    "            raw_data = json_file.read_bytes()\n",
    "            result = chardet.detect(raw_data)\n",
    "            encoding = result['encoding'] or 'utf-8'\n",
    "            text = raw_data.decode(encoding)\n",
    "            data = json.loads(text)\n",
    "            all_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"[오류] {json_file} 읽기 실패: {e}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae333798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON 파일 읽는 중: 100%|██████████| 5/5 [00:00<?, ?file/s]\n",
      "JSON 파일 읽는 중: 100%|██████████| 5/5 [00:00<?, ?file/s]\n",
      "JSON 파일 읽는 중: 100%|██████████| 5/5 [00:00<00:00, 997.79file/s]\n",
      "JSON 파일 읽는 중: 100%|██████████| 5/5 [00:00<00:00, 583.60file/s]\n",
      "JSON 파일 읽는 중: 100%|██████████| 5/5 [00:00<00:00, 756.82file/s]\n",
      "JSON 파일 읽는 중: 100%|██████████| 5/5 [00:00<00:00, 998.93file/s]\n"
     ]
    }
   ],
   "source": [
    "medicine_list = load_all_jsons_from_relative_path(\"data/row_docs/kwon/medicine/3.개방데이터/1.데이터/Training/01.원천데이터\", 5)\n",
    "medical_treatment_list = load_all_jsons_from_relative_path(\"data/row_docs/kwon/medical_treatment/09.필수의료_의학지식_데이터/3.개방데이터/1.데이터/Training/01.원천데이터\", 5)\n",
    "medical_assistance_and_convergence_areas_answer_list = load_all_jsons_from_relative_path(\"data/row_docs/kwon/medical_assistance_and_convergence_areas/Training/OnChwon/answer\", 5)\n",
    "medical_assistance_and_convergence_areas_question_list = load_all_jsons_from_relative_path(\"data/row_docs/kwon/medical_assistance_and_convergence_areas/Training/OnChwon/question\", 5)\n",
    "internal_medicine_and_surgery_answer_list = load_all_jsons_from_relative_path(\"data/row_docs/kwon/internal_medicine_and_surgery/Training/OnChwon/answer\", 5)\n",
    "internal_medicine_and_surgery_question_list = load_all_jsons_from_relative_path(\"data/row_docs/kwon/internal_medicine_and_surgery/Training/OnChwon/question\", 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2c3095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_id': '21001_1', 'domain': 1, 'source': 7, 'source_spec': '안과학회', 'creation_year': '2024', 'content': '눈꺼풀속말림(Entropion)의 치료는 원인에 따라 수술을 시행하는 것이 원칙입니다. 일반적으로 만 5세까지는 염증이 발생할 때마다 안약 등 보존적 치료를 통해 관리합니다. 그러나 시력 저하, 만성적인 각막 염증, 각막 혼탁 등의 합병증이 우려되는 경우에는 만 5세 이후에 수술을 고려합니다. 만 5세 이전에 수술을 잘 시행하지 않는 이유는 다음과 같습니다. 첫째, 5세 정도가 되면 소아의 얼굴에서 젖살이 빠지면서 눈꺼풀이 자연스럽게 원래의 위치로 돌아가는 경우가 많기 때문입니다. 둘째, 5세 이전의 소아는 속눈썹이 비교적 얇고 부드러워 각막에 심각한 손상을 일으킬 가능성이 낮기 때문입니다.'}\n",
      "{'c_id': '3134_1', 'domain': 2, 'source': 7, 'source_spec': '서울대학교병원', 'creation_year': 'null', 'content': '1. 본 시술은 척수 및 신경근에서 발생하는 다양한 급성 및 만성 통증의 진단과 치료를 목적으로 시행됩니다. 2. 시술을 받지 않을 경우, 척추 분절 통증 또는 신경근 증상이 지속되거나 악화될 수 있습니다. 드물게 신경근병증이 급격히 악화되어 감각 이상, 근력 저하 등의 증상이 나타날 수 있습니다. 3. 예정된 시술 외에도 약물 요법, 물리치료, 재활치료 등을 먼저 시도하거나 병행할 수 있습니다. 4. 시술의 목적은 요추, 미추, 경추, 흉추 부위의 통증을 줄이기 위해 약물을 주입하여 척수 분절성 통증을 완화하고, 근육 이완과 혈액 순환 개선에 기여하는 것입니다. 5. 시술 방법 및 내용: 1) 방사선 장비로 척추 구조를 확인한 후, 통증 부위에 바늘을 삽입하고 조영제를 주입하여 정확한 위치를 확인합니다. 이후 약물을 주입합니다. 2) 시술 예상 소요 시간은 약 10분입니다. 3) 환자의 상태에 따라 시술 방법이나 범위가 변경될 수 있으며, 이 경우 사전에 설명 후 동의를 구합니다. 긴급 상황에서는 시술 후 즉시 설명이 이루어집니다. 4) 수혈 가능성은 매우 낮습니다. 5) 환자 상태나 의료기관 사정으로 주치의가 변경될 수 있으며, 가능한 경우 사전에 설명하고 동의를 구합니다. 긴급 상황에서는 시술 후 즉시 설명합니다. 6. 발생 가능한 합병증, 후유증, 부작용 및 문제 발생 시 조치 사항: 경막 천자로 인해 지주막하 차단, 감염, 출혈, 일시적인 통증 증가, 혈관 또는 추간판 천자, 약물의 혈관 내 주입, 신경 손상, 이상 감각, 효과 부족 등이 드물게 발생할 수 있습니다. 문제가 발생할 경우 약물 투여, 추가 시술, 수술 또는 입원이 필요할 수 있습니다. 발열, 오한, 두통, 어지러움, 시술 부위의 통증 악화, 팔 다리 근력 저하, 의식 소실 등이 발생하면 즉시 병원을 방문해야 합니다. 7. 시술 전후 환자가 준수해야 할 사항: 시술 전: 항응고제, 항혈소판제 등의 약물 복용 중단에 대해 의사와 상담하십시오. 경추나 상위 흉추 시술 시 6시간 금식이 필요합니다. 약물 부작용 경험이 있다면 반드시 의사와 상의하십시오. 시술 후: 20-30분간 안정을 취하십시오. 감염 예방을 위해 24시간 동안 시술 부위를 물에 접촉시키지 말고, 3일간 수영, 사우나 등을 피하십시오. 흉부 경막 외 차단술 후 가슴 답답함, 호흡 곤란이 발생하면 즉시 병원에서 흉부 방사선 검사를 받으십시오. 8. 기타 추가 설명: 치료 효과와 지속 기간은 개인차가 있습니다. 1회 시술로 효과가 불충분할 경우 추가 치료나 시술이 필요할 수 있습니다. 시술 중 요통과 하지 방사통은 정상적인 증상이며, 심한 경우 정맥을 통해 진통제를 추가 투여할 수 있습니다. 본 시술 관련 데이터는 향후 임상 연구에 활용될 수 있습니다. 정확한 진단을 위해 추가 특수 검사가 시행될 수 있으며, 이에 따른 추가 비용이 발생할 수 있습니다.'}\n",
      "{'fileName': 'HC-A-02514695', 'disease_category': '귀코목질환', 'disease_name': {'kor': '고막염', 'eng': 'Myringitis'}, 'department': ['이비인후과'], 'intention': '약물', 'answer': {'intro': '고막염은 중이염이 발생하거나 고막에 염증이 발생하여 귀가 아픈 증상을 말합니다. 주로 어린 아이들에게서 나타나며, 증상의 정도와 심각성에 따라 적절한 치료가 필요합니다.', 'body': '치료에는 다양한 약물이 사용됩니다. 진통제는 통증을 완화하기 위해 사용되며, 대부분의 고막염 환자에게 적용됩니다. 항염증 효과가 있는 약물은 염증을 억제하고 귀를 보호하는 데 도움을 줍니다. 통증 완화를 위해 귀 통증을 완화하는 약물도 사용할 수 있습니다.', 'conclusion': '고막염의 치료는 환자의 상태에 따라 달라질 수 있으므로 정확한 진단과 처방이 필요합니다. 의사와의 상담을 통해 적절한 치료를 받는 것이 중요합니다.'}, 'num_of_words': 75}\n",
      "{'fileName': 'HC-Q-0716534', 'participantsInfo': {'participantID': 'QC197', 'gender': '남성', 'age': '50대 이상', 'occupation': '생산/노무직', 'history': False, 'rPlace': '부산/대구/울산/경상'}, 'disease_category': '귀코목질환', 'disease_name': {'kor': '고막염', 'eng': 'Myringitis'}, 'intention': '검진', 'question': '고막염을 조기에 발견하기 위해 어떤 검진을 권장하시나요?', 'entities': [{'id': 0, 'text': '고막염', 'entity': '질환명', 'position': 0}], 'num_of_words': 7}\n",
      "{'fileName': 'HC-A-03614230', 'disease_category': '감염성질환', 'disease_name': {'kor': 'HIV 감염', 'eng': 'HIV infection'}, 'department': ['피부과'], 'intention': '검진', 'answer': {'intro': 'HIV 감염 검사는 매우 중요한 절차입니다. HIV 감염 검사는 조기에 HIV 바이러스 감염 여부를 확인하고 적절한 치료를 받을 수 있게 도와줍니다.', 'body': 'HIV 감염 검사에는 2가지 주요한 요소가 포함됩니다. 첫째, HIV 항체 검사는 HIV에 감염된 지 여부를 확인하는 데 사용됩니다. 두 번째, HIV 항체/항원 결합 검사는 HIV에 감염되었을 때 항체와 항원이 존재하는지를 파악하는 검사입니다.', 'conclusion': 'HIV 감염 검사는 HIV 바이러스에 대한 조기 진단과 조기 치료를 가능하게 해줍니다. 이 검사들은 환자의 건강 상태를 평가하고 적절한 치료 계획을 세울 수 있도록 도와줍니다.'}, 'num_of_words': 78}\n",
      "{'fileName': 'HC-Q-1160428', 'participantsInfo': {'participantID': 'QC048', 'gender': '남성', 'age': '50대 이상', 'occupation': '기타', 'history': False, 'rPlace': '서울/경기/인천'}, 'disease_category': '감염성질환', 'disease_name': {'kor': 'HIV 감염', 'eng': 'HIV infection'}, 'intention': '검진', 'question': 'HIV 감염을 의심하고 있는데, 어떤 곳에서 검진을 받아야 할까요?', 'entities': [{'id': 0, 'text': 'HIV 감염', 'entity': '질환명', 'position': 0}], 'num_of_words': 9}\n"
     ]
    }
   ],
   "source": [
    "print(medicine_list[0])\n",
    "print(medical_treatment_list[0])\n",
    "print(medical_assistance_and_convergence_areas_answer_list[0])\n",
    "print(medical_assistance_and_convergence_areas_question_list[0])\n",
    "print(internal_medicine_and_surgery_answer_list[0])\n",
    "print(internal_medicine_and_surgery_question_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5f5f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.82.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.43-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.2-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.82.1-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/720.5 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.5 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 524.3/720.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 720.5/720.5 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.2 MB/s eta 0:00:00\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.43-py3-none-any.whl (361 kB)\n",
      "Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl (134 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.2 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.0 MB 1.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/15.0 MB 1.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.0/15.0 MB 1.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.3/15.0 MB 1.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.6/15.0 MB 1.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.8/15.0 MB 1.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 2.1/15.0 MB 1.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.4/15.0 MB 1.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.6/15.0 MB 1.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.9/15.0 MB 1.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 3.1/15.0 MB 1.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 3.1/15.0 MB 1.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 3.4/15.0 MB 1.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.7/15.0 MB 1.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 3.9/15.0 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.2/15.0 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 4.5/15.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 4.7/15.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.0/15.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.2/15.0 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 5.5/15.0 MB 1.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.8/15.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.0/15.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.0/15.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.3/15.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.6/15.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.8/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.1/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.3/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.6/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.9/15.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 8.1/15.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.4/15.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.7/15.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.9/15.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.9/15.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 9.2/15.0 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.4/15.0 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.7/15.0 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.0/15.0 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 10.2/15.0 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 10.5/15.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.7/15.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.0/15.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 11.3/15.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 11.5/15.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.8/15.0 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.1/15.0 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.3/15.0 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.3/15.0 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.6/15.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 12.8/15.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.1/15.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.4/15.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.6/15.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 13.9/15.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.2/15.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.4/15.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/15.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/894.0 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/894.0 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 894.0/894.0 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.2-cp310-cp310-win_amd64.whl (294 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, regex, pydantic-core, packaging, orjson, jsonpatch, jiter, greenlet, distro, async-timeout, annotated-types, tiktoken, SQLAlchemy, requests-toolbelt, pydantic, faiss-cpu, openai, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\n",
      "   ----- ----------------------------------  3/23 [regex]\n",
      "  Attempting uninstall: packaging\n",
      "   ----- ----------------------------------  3/23 [regex]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ----- ----------------------------------  3/23 [regex]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ----- ----------------------------------  3/23 [regex]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ----- ----------------------------------  3/23 [regex]\n",
      "   -------- -------------------------------  5/23 [packaging]\n",
      "   --------------- ------------------------  9/23 [greenlet]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   ------------------------ --------------- 14/23 [SQLAlchemy]\n",
      "   --------------------------- ------------ 16/23 [pydantic]\n",
      "   --------------------------- ------------ 16/23 [pydantic]\n",
      "   --------------------------- ------------ 16/23 [pydantic]\n",
      "   ----------------------------- ---------- 17/23 [faiss-cpu]\n",
      "   ----------------------------- ---------- 17/23 [faiss-cpu]\n",
      "   ----------------------------- ---------- 17/23 [faiss-cpu]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   ------------------------------- -------- 18/23 [openai]\n",
      "   --------------------------------- ------ 19/23 [langsmith]\n",
      "   --------------------------------- ------ 19/23 [langsmith]\n",
      "   ---------------------------------- ----- 20/23 [langchain-core]\n",
      "   ---------------------------------- ----- 20/23 [langchain-core]\n",
      "   ---------------------------------- ----- 20/23 [langchain-core]\n",
      "   ---------------------------------- ----- 20/23 [langchain-core]\n",
      "   ------------------------------------ --- 21/23 [langchain-text-splitters]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   -------------------------------------- - 22/23 [langchain]\n",
      "   ---------------------------------------- 23/23 [langchain]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.41 annotated-types-0.7.0 async-timeout-4.0.3 distro-1.9.0 faiss-cpu-1.11.0 greenlet-3.2.2 jiter-0.10.0 jsonpatch-1.33 langchain-0.3.25 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langsmith-0.3.43 openai-1.82.1 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 regex-2024.11.6 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.9.0 typing-inspection-0.4.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "# data_list = load_all_json_recursive(\"./data/processed_docs/\")\n",
    "!pip install openai langchain faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1a9449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.5 MB 1.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.8/10.5 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.0/10.5 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.3/10.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/10.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.8/10.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.1/10.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.1/10.5 MB 1.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.4/10.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.6/10.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.9/10.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.1/10.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.4/10.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.4/10.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.7/10.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 3.9/10.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.2/10.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.5/10.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 4.7/10.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.0/10.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.2/10.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.5/10.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.8/10.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.0/10.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.3/10.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.3/10.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.6/10.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.8/10.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.1/10.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.3/10.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.6/10.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.9/10.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.1/10.5 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.4/10.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.7/10.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.9/10.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.2/10.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.4/10.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.0/10.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.32.3-py3-none-any.whl (512 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------- ------------------- 3/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [tokenizers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [transformers]\n",
      "   ---------------------------------------- 6/6 [transformers]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.1 huggingface-hub-0.32.3 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09d78d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.0-cp310-cp310-win_amd64.whl (212.5 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------------------------------------- 0/4 [mpmath]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [sympy]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   -------------------- ------------------- 2/4 [networkx]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ------------------------------ --------- 3/4 [torch]\n",
      "   ---------------------------------------- 4/4 [torch]\n",
      "\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aacc5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (0.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee81f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141b93cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52011da4545d411a815230f6cbc22de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\chatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--jhgan--ko-sroberta-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd96fe5ee474e10b7233666281ca5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee45f9870f34f2e90406191fcc7d58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 임베딩 모델 로드 (jhgan/ko-sroberta-multitask)\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6e74369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 카테고리별 샘플 데이터 준비 (전처리 포함)\n",
    "def prepare_category_db(data_list, category):\n",
    "    processed = []\n",
    "    for item in data_list:\n",
    "        if isinstance(item, dict):\n",
    "            if 'content' in item:\n",
    "                text = item['content']\n",
    "            elif 'question' in item:\n",
    "                text = item['question']\n",
    "            elif 'answer' in item:\n",
    "                ans = item['answer']\n",
    "                text = ' '.join([ans.get(k, '') for k in ['intro', 'body', 'conclusion']])\n",
    "            else:\n",
    "                text = str(item)\n",
    "        else:\n",
    "            text = str(item)\n",
    "        processed.append({'content': text.strip(), 'category': category})\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2233192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sentence_transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sentence_transformers) (2.7.0)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sentence_transformers) (0.32.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sentence_transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sentence_transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.4.26)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 1.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/11.1 MB 1.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.6/11.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.4/11.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.7/11.1 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.9/11.1 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.2/11.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.5/11.1 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.1 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.0/11.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.8/11.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.1/11.1 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.1 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.1 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.1 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.9/11.1 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.2/11.1 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.4/11.1 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.4/11.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.2/11.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/41.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/41.3 MB 1.1 MB/s eta 0:00:37\n",
      "    --------------------------------------- 0.8/41.3 MB 1.1 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 1.0/41.3 MB 1.1 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 1.3/41.3 MB 1.2 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 1.6/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 1.8/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.1/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.4/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.4/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.6/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.9/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.1/41.3 MB 1.1 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.4/41.3 MB 1.1 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 3.7/41.3 MB 1.1 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 3.9/41.3 MB 1.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 4.2/41.3 MB 1.1 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 4.5/41.3 MB 1.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 4.5/41.3 MB 1.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 4.7/41.3 MB 1.1 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 5.0/41.3 MB 1.1 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 5.2/41.3 MB 1.1 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 5.5/41.3 MB 1.1 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 5.8/41.3 MB 1.1 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 6.0/41.3 MB 1.1 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 6.3/41.3 MB 1.1 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 6.6/41.3 MB 1.1 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 6.6/41.3 MB 1.1 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 6.8/41.3 MB 1.1 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 7.1/41.3 MB 1.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 7.3/41.3 MB 1.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 7.6/41.3 MB 1.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 7.9/41.3 MB 1.1 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 8.1/41.3 MB 1.1 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 8.4/41.3 MB 1.1 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 8.7/41.3 MB 1.1 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 8.9/41.3 MB 1.1 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 9.2/41.3 MB 1.1 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 9.2/41.3 MB 1.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 9.4/41.3 MB 1.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 9.7/41.3 MB 1.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.0/41.3 MB 1.1 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 10.2/41.3 MB 1.1 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 10.5/41.3 MB 1.1 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 10.7/41.3 MB 1.1 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 11.0/41.3 MB 1.1 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 11.3/41.3 MB 1.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 11.5/41.3 MB 1.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 11.5/41.3 MB 1.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 11.8/41.3 MB 1.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 12.1/41.3 MB 1.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 12.3/41.3 MB 1.1 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 12.6/41.3 MB 1.1 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 12.8/41.3 MB 1.1 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 13.1/41.3 MB 1.1 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 13.4/41.3 MB 1.1 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 13.4/41.3 MB 1.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 13.6/41.3 MB 1.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 13.9/41.3 MB 1.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 14.2/41.3 MB 1.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 14.4/41.3 MB 1.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 14.7/41.3 MB 1.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 14.9/41.3 MB 1.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 15.2/41.3 MB 1.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 15.5/41.3 MB 1.1 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 15.7/41.3 MB 1.1 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 15.7/41.3 MB 1.1 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 16.0/41.3 MB 1.1 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 16.3/41.3 MB 1.1 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 16.5/41.3 MB 1.1 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 16.8/41.3 MB 1.1 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 17.0/41.3 MB 1.1 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 17.3/41.3 MB 1.1 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 17.6/41.3 MB 1.1 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 17.8/41.3 MB 1.1 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 18.1/41.3 MB 1.1 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 18.1/41.3 MB 1.1 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 18.4/41.3 MB 1.1 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 18.6/41.3 MB 1.1 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 18.9/41.3 MB 1.1 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 19.1/41.3 MB 1.1 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 19.4/41.3 MB 1.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 19.7/41.3 MB 1.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 19.9/41.3 MB 1.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 20.2/41.3 MB 1.1 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 20.4/41.3 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 20.7/41.3 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 21.0/41.3 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 21.2/41.3 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 21.2/41.3 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 21.5/41.3 MB 1.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 21.8/41.3 MB 1.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 22.0/41.3 MB 1.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 22.3/41.3 MB 1.1 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 22.5/41.3 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 22.8/41.3 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 23.1/41.3 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 23.3/41.3 MB 1.1 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 23.6/41.3 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 23.9/41.3 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 23.9/41.3 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 24.1/41.3 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 24.4/41.3 MB 1.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 24.6/41.3 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 24.9/41.3 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 25.2/41.3 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 25.4/41.3 MB 1.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 25.7/41.3 MB 1.1 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 26.0/41.3 MB 1.1 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 26.2/41.3 MB 1.1 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 26.2/41.3 MB 1.1 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 26.5/41.3 MB 1.1 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 26.7/41.3 MB 1.1 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 27.0/41.3 MB 1.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 27.3/41.3 MB 1.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 27.5/41.3 MB 1.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 27.8/41.3 MB 1.1 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 28.0/41.3 MB 1.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 28.3/41.3 MB 1.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 28.3/41.3 MB 1.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 28.6/41.3 MB 1.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 28.8/41.3 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 29.1/41.3 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 29.4/41.3 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 29.6/41.3 MB 1.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 29.9/41.3 MB 1.1 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 30.1/41.3 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 30.4/41.3 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 30.7/41.3 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 30.7/41.3 MB 1.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 30.9/41.3 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 31.2/41.3 MB 1.1 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 31.5/41.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 31.7/41.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 32.0/41.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 32.2/41.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 32.5/41.3 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 32.8/41.3 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 33.0/41.3 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 33.3/41.3 MB 1.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 33.6/41.3 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 33.6/41.3 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 33.8/41.3 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 34.1/41.3 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 34.3/41.3 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 34.6/41.3 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 34.9/41.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 35.1/41.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 35.4/41.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 35.7/41.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 35.9/41.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 35.9/41.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 36.2/41.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 36.4/41.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 36.7/41.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 37.0/41.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 37.2/41.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 37.5/41.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 37.7/41.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 38.0/41.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 38.3/41.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 38.3/41.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 38.5/41.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 38.8/41.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 39.1/41.3 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 39.3/41.3 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 39.6/41.3 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 39.8/41.3 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 40.1/41.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  40.4/41.3 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.3 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.6/41.3 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.3 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.3 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 1.1 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence_transformers\n",
      "\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   -------- ------------------------------- 1/5 [scipy]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   ------------------------ --------------- 3/5 [scikit-learn]\n",
      "   -------------------------------- ------- 4/5 [sentence_transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence_transformers]\n",
      "   -------------------------------- ------- 4/5 [sentence_transformers]\n",
      "   ---------------------------------------- 5/5 [sentence_transformers]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1 scipy-1.15.3 sentence_transformers-4.1.0 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b6400a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cccfd824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c09d5476f5247db9a7ccf4b464ae587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab91c9f3671459d9f62543c9c158ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13366d8cf64e418da087d55261ff9df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a283f2549b9a46949ff15cc08bb0e256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dffad2ca46948568611a6840e0e5217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 임베딩 모델 로드 (jhgan/ko-sroberta-multitask)\n",
    "embedder = SentenceTransformer('jhgan/ko-sroberta-multitask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93be8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 전체 카테고리 DB 만들기\n",
    "category_data = (\n",
    "    prepare_category_db(medicine_list, \"medicine\") +\n",
    "    prepare_category_db(medical_treatment_list, \"treatment\") +\n",
    "    prepare_category_db(medical_assistance_and_convergence_areas_answer_list, \"assist_answer\") +\n",
    "    prepare_category_db(medical_assistance_and_convergence_areas_question_list, \"assist_question\") +\n",
    "    prepare_category_db(internal_medicine_and_surgery_answer_list, \"internal_answer\") +\n",
    "    prepare_category_db(internal_medicine_and_surgery_question_list, \"internal_question\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c8b3415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '눈꺼풀속말림(Entropion)의 치료는 원인에 따라 수술을 시행하는 것이 원칙입니다. 일반적으로 만 5세까지는 염증이 발생할 때마다 안약 등 보존적 치료를 통해 관리합니다. 그러나 시력 저하, 만성적인 각막 염증, 각막 혼탁 등의 합병증이 우려되는 경우에는 만 5세 이후에 수술을 고려합니다. 만 5세 이전에 수술을 잘 시행하지 않는 이유는 다음과 같습니다. 첫째, 5세 정도가 되면 소아의 얼굴에서 젖살이 빠지면서 눈꺼풀이 자연스럽게 원래의 위치로 돌아가는 경우가 많기 때문입니다. 둘째, 5세 이전의 소아는 속눈썹이 비교적 얇고 부드러워 각막에 심각한 손상을 일으킬 가능성이 낮기 때문입니다.', 'category': 'medicine'}, {'content': '1. 눈꺼풀속말림과 덧눈꺼풀을 정확히 감별하는 것이 중요합니다. 2. 눈꺼풀속말림은 주로 노인에서 발생하는 경향이 있습니다. 3. 덧눈꺼풀은 주로 소아에서 발생하는 특징이 있습니다.', 'category': 'medicine'}, {'content': '바깥다래끼(External hordeolum)는 눈꺼풀의 바깥쪽에 발생하는 급성 화농성 염증입니다. 이는 주로 속눈썹 모낭이나 그 주변의 피지선(Zeis선 또는 Moll선)에 세균 감염이 발생하여 생깁니다. 가장 흔한 원인균은 황색포도상구균(Staphylococcus aureus)입니다. 초기에는 국소적인 발적, 부종, 통증이 나타나며, 진행되면 고름이 형성될 수 있습니다. 일반적으로 자가 치유가 가능하지만, 심한 경우 항생제 치료나 외과적 배농이 필요할 수 있습니다.', 'category': 'medicine'}, {'content': \"1. 바깥다래끼(External hordeolum)는 눈꺼풀에 위치한 짜이스선(Zies gland)과 몰선(Moll's gland)의 급성 화농성 염증입니다. 2. 이 염증은 주로 포도알균(Staphylococcus)이 원인으로 작용합니다. 3. 바깥다래끼는 눈꺼풀 표면에 가까운 부위에서 발생하며, 종창(부기), 통증, 그리고 농양(고름집)을 동반합니다. 4. 염증이 진행되면 피부를 통해 고름이 배출됩니다(배농).\", 'category': 'medicine'}, {'content': '1. 바깥다래끼(External hordeolum)는 초기 단계에서 눈꺼풀 가장자리에 발적(피부가 붉어짐)과 소양감(가려움증)이 나타납니다. 2. 시간이 지나면서 해당 부위가 붓고 통증이 발생합니다. 3. 약 4~5일이 경과하면 통증이 점차 감소하며, 염증 부위에 농양(고름)이 형성됩니다. 4. 이후 농양이 피부를 통해 배출됩니다(배농).', 'category': 'medicine'}, {'content': '1. 본 시술은 척수 및 신경근에서 발생하는 다양한 급성 및 만성 통증의 진단과 치료를 목적으로 시행됩니다. 2. 시술을 받지 않을 경우, 척추 분절 통증 또는 신경근 증상이 지속되거나 악화될 수 있습니다. 드물게 신경근병증이 급격히 악화되어 감각 이상, 근력 저하 등의 증상이 나타날 수 있습니다. 3. 예정된 시술 외에도 약물 요법, 물리치료, 재활치료 등을 먼저 시도하거나 병행할 수 있습니다. 4. 시술의 목적은 요추, 미추, 경추, 흉추 부위의 통증을 줄이기 위해 약물을 주입하여 척수 분절성 통증을 완화하고, 근육 이완과 혈액 순환 개선에 기여하는 것입니다. 5. 시술 방법 및 내용: 1) 방사선 장비로 척추 구조를 확인한 후, 통증 부위에 바늘을 삽입하고 조영제를 주입하여 정확한 위치를 확인합니다. 이후 약물을 주입합니다. 2) 시술 예상 소요 시간은 약 10분입니다. 3) 환자의 상태에 따라 시술 방법이나 범위가 변경될 수 있으며, 이 경우 사전에 설명 후 동의를 구합니다. 긴급 상황에서는 시술 후 즉시 설명이 이루어집니다. 4) 수혈 가능성은 매우 낮습니다. 5) 환자 상태나 의료기관 사정으로 주치의가 변경될 수 있으며, 가능한 경우 사전에 설명하고 동의를 구합니다. 긴급 상황에서는 시술 후 즉시 설명합니다. 6. 발생 가능한 합병증, 후유증, 부작용 및 문제 발생 시 조치 사항: 경막 천자로 인해 지주막하 차단, 감염, 출혈, 일시적인 통증 증가, 혈관 또는 추간판 천자, 약물의 혈관 내 주입, 신경 손상, 이상 감각, 효과 부족 등이 드물게 발생할 수 있습니다. 문제가 발생할 경우 약물 투여, 추가 시술, 수술 또는 입원이 필요할 수 있습니다. 발열, 오한, 두통, 어지러움, 시술 부위의 통증 악화, 팔 다리 근력 저하, 의식 소실 등이 발생하면 즉시 병원을 방문해야 합니다. 7. 시술 전후 환자가 준수해야 할 사항: 시술 전: 항응고제, 항혈소판제 등의 약물 복용 중단에 대해 의사와 상담하십시오. 경추나 상위 흉추 시술 시 6시간 금식이 필요합니다. 약물 부작용 경험이 있다면 반드시 의사와 상의하십시오. 시술 후: 20-30분간 안정을 취하십시오. 감염 예방을 위해 24시간 동안 시술 부위를 물에 접촉시키지 말고, 3일간 수영, 사우나 등을 피하십시오. 흉부 경막 외 차단술 후 가슴 답답함, 호흡 곤란이 발생하면 즉시 병원에서 흉부 방사선 검사를 받으십시오. 8. 기타 추가 설명: 치료 효과와 지속 기간은 개인차가 있습니다. 1회 시술로 효과가 불충분할 경우 추가 치료나 시술이 필요할 수 있습니다. 시술 중 요통과 하지 방사통은 정상적인 증상이며, 심한 경우 정맥을 통해 진통제를 추가 투여할 수 있습니다. 본 시술 관련 데이터는 향후 임상 연구에 활용될 수 있습니다. 정확한 진단을 위해 추가 특수 검사가 시행될 수 있으며, 이에 따른 추가 비용이 발생할 수 있습니다.', 'category': 'treatment'}, {'content': '1. 경막외 카테터 삽입술은 급성 및 만성 통증을 완화하고 치료하기 위해 시행됩니다. 2. 시술을 하지 않을 경우, 효과적인 통증 관리가 어려워지고, 정맥으로 많은 양의 진통제를 투여해야 하며, 이로 인해 졸음, 어지러움, 메스꺼움, 구토, 호흡 억제 등의 부작용이 발생할 수 있습니다. 통증이 적절히 관리되지 않으면 회복이 지연되고 입원 기간이 길어질 수 있습니다. 3. 경막외 자가통증조절법 외에도 간헐적으로 경구 또는 정맥으로 진통제를 투여하거나, 정맥 자가통증조절법을 사용할 수 있는 대안이 있습니다. 4. 경막외 공간에 카테터를 삽입하여 약물을 지속적 또는 반복적으로 투여함으로써 통증을 줄입니다. 적은 양의 진통제로도 효과를 얻을 수 있어 부작용을 최소화하며, 폐 합병증과 위장관계 폐색을 줄이는 데 도움을 줍니다. 또한, 통증 관리를 통해 상처 치유 지연, 스트레스, 수면 장애 등을 최소화할 수 있습니다. 5. 시술 과정은 경막외 공간에 바늘을 삽입하고 정확한 위치를 확인한 후, 바늘을 통해 얇은 관(카테터)을 삽입하여 약물을 투여하는 방식으로 진행됩니다. 시술 시간은 약 20분 정도 소요됩니다. 환자의 상태에 따라 시술 방법이 변경되거나 범위가 확장될 수 있으며, 사전에 설명과 동의를 구합니다. 긴급한 경우에는 시술 후 즉시 이유와 결과를 설명합니다. 본 시술에서 수혈이 필요할 가능성은 매우 낮습니다. 환자의 상태나 의료기관의 상황에 따라 주치의가 변경될 수 있으며, 이 경우 사전에 설명과 동의를 구하거나 긴급 상황에서는 시술 후 설명합니다. 6. 시술로 인해 발생할 수 있는 합병증으로는 경막천자로 인한 지주막하 차단(근력 약화, 두통, 저혈압), 감염, 출혈, 시술 부위의 일시적 통증 증가, 혈관 천자, 추간판 천자, 약물의 혈관 내 주입, 신경 손상 등이 있습니다. 근력 약화나 저혈압은 대개 일시적이지만, 심각한 경우 침상 안정이나 혈압 상승제 사용 등의 처치가 필요할 수 있습니다. 감염 예방을 위해 철저한 손 위생과 소독 절차를 준수하지만, 면역력이 저하된 경우 감염이 발생할 수 있으며, 항생제 투여나 수술적 제거가 필요할 수 있습니다. 시술 부위의 혈관 손상으로 출혈이 발생할 수 있으나 대부분 경미하거나 단기간에 그칩니다. 지주막하 혈종이 발생할 경우 신경 손상을 초래할 수 있어 추가적인 약물 치료나 수술이 필요할 수 있습니다. 시술 중 바늘로 인한 통증이 있을 수 있으나, 이를 최소화하기 위해 국소마취제를 사용합니다. 약물이 혈관 내로 주입될 경우 드물게 발작, 부정맥, 심정지가 발생할 수 있으며, 의식 저하나 특이한 냄새를 느끼는 등의 증상이 있으면 즉시 의료진에게 알려야 합니다. 척추 신경 손상 시 이상 감각이나 하지 마비가 발생할 수 있으며, 흉부 경막외 시술 시 흉막 천자로 인한 기흉 또는 혈흉의 가능성도 있습니다. 이러한 위험을 최소화하기 위해 다양한 영상 장치를 활용하여 정확하고 효과적인 시술을 위해 노력하고 있습니다. 합병증 발생 시 약물 치료나 수술적 치료가 필요할 수 있습니다. 경막외 공간은 매우 협소하여 카테터 삽입에 고도의 기술이 요구되며, 환자의 해부학적 구조 이상 등으로 인해 시술이 실패하거나 효과가 없을 수 있습니다. 이 경우 시술을 반복하거나 다른 통증 조절법을 시도할 수 있습니다. 각 부작용에 따라 약물 투여, 추가 시술이나 수술, 입원 등이 필요할 수 있습니다. 7. 시술 전에는 복용 중인 약물이 있다면 의사와 상의하여 중단 여부를 결정해야 하며, 약물 부작용 이력이 있는 경우 반드시 의사에게 알려야 합니다. 마취 중 시행 시 금식이 필요하며, 의식이 있는 상태에서 시행할 경우 의사와 상의해야 합니다. 시술 후에는 20-30분 동안 안정을 취하며, 감염 예방을 위해 시술 부위를 물에 닿지 않게 주의해야 합니다. 카테터 제거 후에도 3일간 시술 부위를 물에 노출시키지 않아야 합니다. 8. 치료에도 불구하고 증상이 개선되지 않을 수 있으며, 이 경우 추가적으로 여러 차례의 신경 차단술을 시행할 수 있습니다. 본 시술과 관련된 정보는 향후 임상 연구 데이터로 활용될 수 있습니다. 시술 후 정확한 진단을 위해 추가 특수 검사가 필요할 수 있으며, 이 경우 추가 비용이 청구될 수 있습니다.', 'category': 'treatment'}, {'content': '1. 본 시술은 다양한 급성 및 만성 통증을 완화하고 치료하기 위해 시행됩니다. 2. 경막외 카테터 삽입술을 시행하지 않을 경우, 효과적인 통증 관리가 어려워질 수 있습니다. 정맥으로 진통제를 투여할 경우 상대적으로 많은 양이 필요하며, 이로 인해 졸음, 어지러움, 메스꺼움, 구토, 호흡 억제 등의 부작용이 발생할 수 있습니다. 적절한 통증 관리가 이루어지지 않으면 회복이 지연되어 입원 기간이 길어질 수 있습니다. 3. 경막외 자가 통증 조절법 외에도 간헐적인 경구 또는 정맥 진통제 투여, 정맥 자가 통증 조절법 등의 대안이 있습니다. 4. 경막외 공간에 카테터를 삽입하여 지속적 또는 반복적으로 해당 척수 분절에 약물을 투여함으로써 통증을 경감시킵니다. 적은 양의 진통제로도 효과를 내어 진통제의 부작용(운동 및 감각 저하, 구역, 구토, 졸림 등)을 최소화하며, 폐 합병증과 위장관계 폐색을 줄이는 효과가 있습니다. 또한, 통증 관리를 통해 상처 치유 지연, 스트레스, 수면 장애 등을 최소화할 수 있습니다. 5. 시술 과정은 다음과 같습니다. 1) 경막외 공간에 바늘을 삽입하고 주사기를 이용해 정확한 위치를 확인합니다. 이후 삽입된 바늘을 통해 얇은 관(카테터)을 넣습니다. 이 카테터를 통해 며칠에 걸쳐 지속적 또는 반복적으로 적절한 약물을 주입합니다. 2) 시술은 약 20분 정도 소요될 것으로 예상됩니다. 3) 환자의 상태에 따라 시술 방법이 변경되거나 범위가 확장될 수 있으며, 사전에 설명하고 동의를 구합니다. 긴급한 경우, 시술 후 즉시 이유와 결과를 설명합니다. 4) 본 시술에서 수혈이 필요할 가능성은 매우 낮습니다. 5) 환자의 상태나 의료기관의 상황(응급 환자 발생, 시술 의사의 건강 문제 등)으로 인해 주치의(시술 의사)가 변경될 수 있습니다. 이 경우 시술 전에 구체적인 사유를 설명하고 동의를 구할 예정입니다. 긴급한 상황으로 사전 동의가 불가능한 경우, 시술 후 즉시 변경 사유와 결과를 설명드립니다. 6. 발생 가능한 합병증, 후유증, 부작용 및 문제 발생 시 조치 사항은 다음과 같습니다. 경막천자로 인해 지주막하 차단(근력 약화, 두통, 저혈압), 감염, 출혈, 시술 부위의 일시적 통증 증가, 혈관 천자, 추간판 천자, 약물의 혈관 내 주입, 신경 손상 및 그로 인한 합병증(하지 마비 등), 이상 감각, 효과 없음 등이 발생할 수 있습니다. 근력 약화나 저혈압은 일시적으로 나타날 수 있으며, 심각한 경우 침상 안정, 혈압 상승제 사용 등의 처치가 필요할 수 있습니다. 이러한 증상은 대개 오래 지속되지 않으나, 의료진의 면밀한 관찰이 필요할 수 있습니다. 감염 예방을 위해 철저한 손 위생과 소독 절차를 준수하고 있으나, 면역력이 저하된 경우 감염이 발생할 수 있습니다. 이 경우 항생제 투여나 수술적 제거가 필요할 수 있습니다. 시술 부위의 혈관 손상으로 인한 출혈이 발생할 수 있으나, 대부분 경미하거나 단기간에 그칩니다. 지주막하 혈종이 발생할 경우 신경 손상을 일으킬 수 있으므로 추가적인 약물 치료나 수술이 필요할 수 있습니다. 시술 과정에서 바늘로 인한 통증이 있을 수 있으나, 이를 최소화하기 위해 국소 마취제를 사용합니다. 약물이 혈관 내로 주입될 경우 드물게 발작, 부정맥, 심정지가 발생할 수 있습니다. 의식 저하나 특이한 냄새를 느끼는 등의 증상이 있으면 즉시 의료진에게 알려주시기 바랍니다. 시술 중 척추 신경 손상 시 이상 감각이나 하지 마비가 발생할 수 있습니다. 흉부 경막외 시술 시 흉막 천자로 인한 기흉 또는 혈흉의 가능성도 있습니다. 이러한 위험을 최소화하기 위해 다양한 영상 장치를 활용하여 정확하고 효과적인 시술을 위해 노력하고 있습니다. 합병증 발생 시 약물 치료나 수술적 치료가 필요할 수 있습니다. 경막외 공간은 매우 협소하여 카테터 삽입에 고도의 기술이 요구됩니다. 환자의 해부학적 구조 이상 등으로 인해 시술이 실패하거나 효과가 없을 수 있습니다. 이 경우 시술을 반복하거나 다른 통증 조절법을 시도할 수 있습니다. 각 부작용에 따라 약물 투여, 추가 시술이나 수술, 입원 등이 필요할 수 있습니다. 7. 시술 전후 환자가 준수해야 할 사항은 다음과 같습니다. 1) 시술 전 복용 중인 약물이 있다면 의사와 상의하여 중단 여부를 결정해야 합니다. 약물 부작용 이력이 있는 경우 반드시 의사에게 알려주십시오. 마취 중 시술을 시행할 경우 반드시 금식해야 하며, 의식이 있는 상태에서 시술을 시행할 경우 의사와 상의하시기 바랍니다. 2) 시술 후 20-30분 동안 안정을 취하며, 감염 예방을 위해 시술 부위를 물에 닿지 않게 주의해야 합니다. 카테터 제거 후에도 3일간 시술 부위를 물에 노출시키지 않아야 합니다. 8. 치료에도 불구하고 증상이 개선되지 않을 수 있으며, 이 경우 추가적으로 여러 차례의 신경 차단술을 시행할 수 있습니다. 본 시술과 관련된 정보는 향후 임상 연구 데이터로 활용될 수 있습니다. 시술 후 정확한 진단을 위해 추가 특수 검사가 필요할 수 있으며, 이 경우 추가 비용이 청구될 수 있습니다.', 'category': 'treatment'}, {'content': '1. 환자 상태 및 특이사항 이 시술은 뇌척수액 유출로 인해 증상이 의심되는 환자에게 치료 목적으로 시행됩니다. 2. 시술을 하지 않을 경우의 예후 뇌척수액 유출로 인해 발생하는 두통 등의 증상이 지속될 가능성이 있습니다. 3. 예정된 시술 외에 시행 가능한 다른 방법 약물 치료 등을 먼저 시도하거나 병행할 수 있습니다. 수일간 침상 안정, 충분한 수액 공급, 카페인 투여 등을 시행하며 경과를 관찰한 후, 증상이 호전되지 않거나 악화되면 본 시술을 진행하게 됩니다. 이 외에도 생리식염수를 이용한 경막외 봉합술, 생체적합 접착제(fibrin glue)를 사용하는 방법, 지주막하 생리식염수 투여 등의 방법이 있으나, 실제로 많이 사용되지는 않습니다. 최종적으로는 수술적 방법까지 고려할 수 있습니다. 4. 시술의 목적, 필요성, 효과 척추마취나 요추천자 등 경막을 천자하는 시술 이후 또는 자발적으로 뇌척수액 유출이 발생하여 두개내 저압으로 인한 체위성 두통이 나타날 수 있습니다. 본 시술은 환자의 혈액을 채취하여 경막외 공간에 주입함으로써 유출 부위를 막고, 감소된 뇌압을 회복시켜 두통을 완화하는 역할을 합니다. 보존적 치료(수액 공급, 침상 안정 등)로 효과가 없을 경우, 이 시술을 통해 두통을 줄이거나 제거합니다. 5. 시술의 방법 및 내용 1) 시술 과정 방사선 영상 증강 장치를 이용하여 척추 구조물을 확인합니다. 경막외 공간에 바늘을 삽입한 후 조영제를 사용하여 경막외 공간을 확인합니다. 환자로부터 혈액을 채취하여 삽입된 바늘을 통해 경막외 공간에 자가 혈액을 주입합니다. 시술 중 경막 천자가 발생하거나 척추 구조상 접근이 어려운 경우, 척추의 다른 위치에서 추가로 시술을 시행할 수 있습니다. 2) 시술 예상 소요 시간 약 15분 정도 소요될 것으로 예상됩니다. 3) 시술 방법 변경 및 시술 범위 추가 가능성 환자의 상태에 따라 시술 방법이 변경되거나 범위가 확장될 수 있습니다. 이 경우, 가능하다면 시술 전에 환자나 대리인에게 설명하고 동의를 구할 것입니다. 그러나 시술 중 긴급한 상황으로 인해 사전 설명이 불가능한 경우, 시술 후 즉시 변경 또는 추가 사유와 결과를 설명드리겠습니다. 4) 수혈 가능성 수혈이 필요할 가능성은 매우 낮습니다. 6. 발생 가능한 합병증, 후유증, 부작용 및 문제 발생 시 조치 사항 경막 천자(두통, 저혈압), 감염(농양), 출혈, 일시적인 시술 부위 통증 증가, 혈관 손상, 혈전, 이상 감각, 추간판 천자, 효과 부재 등의 부작용이 발생할 수 있습니다. 각 부작용에 따라 추가적인 치료나 시술, 수술 또는 입원이 필요할 수 있습니다. 원인 불명의 발열, 오한, 두통, 어지러움, 시술 부위의 심각한 통증, 팔이나 다리의 근력 저하, 의식 소실 등이 발생하면 즉시 통증 센터나 응급실에 내원하여 의료진의 조치를 받으셔야 합니다. 7. 시술 전후 환자가 준수해야 할 사항 1) 시술 전 항응고제, 항혈소판제 등 중단해야 할 약물에 대해 의사와 상의하십시오. 경추나 상위 흉추에 시술하는 경우가 아니라면 시술 전 금식할 필요는 없습니다. 약물 부작용 이력이 있다면 반드시 의사에게 알려주십시오. 2) 시술 후 자가 혈액 투여 직후 심한 두통이나 사지 통증이 발생하면 즉시 말씀해 주십시오. 감염 예방을 위해 시술 후 24시간 동안 시술 부위에 물이 닿지 않도록 하고, 시술 후 3일간 수영, 사우나 등을 삼가십시오. 8. 기타 추가 설명 치료 효과와 지속 기간은 개인마다 다를 수 있습니다. 치료에도 불구하고 증상이 개선되지 않을 수 있으며, 이 경우 경막외 혈액 봉합술을 여러 차례 반복할 수 있습니다. 시술 후 정확한 진단을 위해 추가 특수 검사가 필요할 수 있으며, 이 경우 추가 비용이 청구될 수 있습니다.', 'category': 'treatment'}, {'content': '1. 환자의 증상이 안면신경과 관련이 있을 경우, 이를 진단하고 치료하기 위해 시술이 진행됩니다. 2. 시술을 받지 않을 경우, 통증이 지속되거나 악화될 가능성이 있으며, 이로 인해 일상생활에서의 불편함이 계속될 수 있습니다. 3. 시술 외에도 약물치료, 물리치료, 재활치료 등의 방법을 먼저 시도하거나 병행할 수 있습니다. 신경 블록 시술은 환자에 따라 효과가 짧거나 없을 수 있으며, 반복적인 시술이 필요할 수 있습니다. 4. 두경부 영역의 뇌신경 분지에 약물을 주입하여 신경을 안정화시키고, 이를 통해 통증을 완화하는 것이 시술의 주요 목적입니다. 5. 시술 과정은 다음과 같습니다: 얼굴 표면을 촉진하여 신경 분지와 주변 구조물을 확인합니다. 필요시 초음파 장비를 사용할 수 있습니다. 신경 분지 근처에 바늘을 삽입한 후, 이를 통해 적절한 약물을 주입합니다. 시술 시간은 약 10분 정도 소요됩니다. 환자의 상태에 따라 시술 방법이 변경되거나 시술 범위가 추가될 수 있으며, 이 경우 사전에 환자 또는 대리인에게 설명하고 동의를 받습니다. 긴급 상황에서는 시술 후 즉시 설명이 이루어집니다. 시술 중 수혈이 필요할 가능성은 매우 낮습니다. 6. 시술로 인해 발생할 수 있는 합병증, 후유증, 부작용은 다음과 같습니다: 안면부 감각 이상, 안면 및 눈꺼풀 부종, 출혈, 일시적 복시, 어지러움, 메스꺼움, 구토, 외안근 마비, 각막궤양, 신경염, 수막염, 감염 등이 드물게 발생할 수 있습니다. 매우 드물게 호흡 곤란이나 심정지의 위험이 있을 수 있습니다. 문제 발생 시 약물 투여, 추가 시술, 입원 등의 조치가 이루어질 수 있으며, 응급 상황에 대비해 생체 징후를 모니터링하고 필요한 약물과 장비를 준비합니다. 7. 환자가 시술 전후에 준수해야 할 사항은 다음과 같습니다: 시술 전: 항응고제나 항혈소판제 등 중단해야 할 약물이 있는 경우 의사와 상의해야 합니다. 시술 부위에 따라 금식이 요구될 수 있으며, 약물 부작용 이력이 있다면 반드시 의사에게 알려야 합니다. 시술 후: 시술 후 20-30분간 안정을 취해야 하며, 감염 예방을 위해 시술 후 24시간 동안 시술 부위를 물에 닿지 않게 해야 합니다. 또한, 3일간 수영이나 사우나를 피해야 합니다. 8. 기타 추가 설명은 다음과 같습니다: 치료 효과와 지속 기간은 개인마다 다를 수 있습니다. 증상이 호전되지 않을 경우 신경 차단술을 반복적으로 시행할 수 있습니다. 본 시술과 관련된 정보는 향후 임상연구 데이터로 활용될 수 있습니다. 시술 후 정확한 진단을 위해 추가적인 특수 검사가 필요할 수 있으며, 이 경우 추가 비용이 발생할 수 있습니다.', 'category': 'treatment'}, {'content': '고막염은 중이염이 발생하거나 고막에 염증이 발생하여 귀가 아픈 증상을 말합니다. 주로 어린 아이들에게서 나타나며, 증상의 정도와 심각성에 따라 적절한 치료가 필요합니다. 치료에는 다양한 약물이 사용됩니다. 진통제는 통증을 완화하기 위해 사용되며, 대부분의 고막염 환자에게 적용됩니다. 항염증 효과가 있는 약물은 염증을 억제하고 귀를 보호하는 데 도움을 줍니다. 통증 완화를 위해 귀 통증을 완화하는 약물도 사용할 수 있습니다. 고막염의 치료는 환자의 상태에 따라 달라질 수 있으므로 정확한 진단과 처방이 필요합니다. 의사와의 상담을 통해 적절한 치료를 받는 것이 중요합니다.', 'category': 'assist_answer'}, {'content': '고막염의 약물 치료는 통증을 줄이고 염증을 완화하기 위해 다양한 약물이 사용됩니다. 일반적으로는 이부프로펜, 파라세타몰(아세트아미노펜), 아편 유사 제제가 사용됩니다. 이러한 약물들은 통증을 완화시키고 염증을 감소시켜 줍니다. 하지만, 모든 종류의 항생제에 대해서는 특별한 효과가 없습니다. 항생제 사용에는 신중해야 합니다. 따라서, 만약 고막염의 증상이 심한 경우 의사의 조언을 받아야 합니다. 고막염의 약물 치료는 통증을 완화하고 염증을 감소시키기 위해 다양한 약물을 사용하는 것입니다. 개별적인 상황에 따라 의사의 조언을 받아 적절한 약물을 선택하는 것이 중요합니다.', 'category': 'assist_answer'}, {'content': '고막염은 중이염으로 인한 통증으로 인해 다양한 치료법이 사용됩니다. 고막염을 치료하기 위해 이부프로펜, 파라세타몰(아세트아미노펜), 그리고 벤조카인 점안액이 주로 사용됩니다. 이 약물들은 통증을 완화시키고 염증을 감소시키는데 효과적입니다. 또한, 항염증제와 항히스타민제도 사용될 수 있으며, 이러한 약물들은 중이염의 원인 질환을 치료하는 데 도움을 줍니다. 고막염 치료에는 전문가의 지도와 지시를 받으며 약물을 조정하고 치료를 진행해야 합니다.', 'category': 'assist_answer'}, {'content': '고막염은 귀에 발생하는 염증으로 인해 통증을 유발합니다. 이 질병의 약물 치료에는 몇 가지 선택 사항이 있습니다. 1. 비마약성 약물: 마약성 진통제로 알려진 비마약성 약물을 이용하는 것은 고막염 환자의 통증을 완화하는 데 도움이 될 수 있습니다. 예를 들어, 이부프로펜, 파라세타몰(아세트아미노펜) 및 벤조카인 점안액이 이에 포함됩니다. 이러한 약물은 통증을 줄여주고 염증을 감소시키는 효과가 있습니다. 2. 스테로이드 약물: 스테로이드 약물은 고막염의 염증을 완화하는 데 도움이 될 수 있습니다. 특히, 이소니아지드와 같은 약물은 효과가 좋고 부작용이 적습니다. 3. 항염증 약물: 특히 스테로이드나 항염증 약물과 같은 약물은 귀에 염증이 발생했을 때 염증을 억제하는 데 사용됩니다. 4. 항진균 약물: 항진균 약물은 귀의 감염을 억제하는 데 도움이 될 수 있습니다. 5. 항우울제: 항우울제는 불안, 우울증, 스트레스 및 불면증 증상을 완화하는 데 도움이 됩니다. 6. 항생제 및 항염증 약물: 이들 약물은 감염을 치료하고 귀의 염증을 완화시키는 데 도움이 됩니다. 고막염 환자의 경우, 의사의 처방에 따라 약물을 복용하는 것이 중요합니다. 적절한 약물 복용은 고막염의 증상 완화와 감염 관리에 도움을 줄 수 있습니다. 그러나 약물 복용 전에 의사와 상담하여 자신의 상황을 평가하고 적절한 약물을 선택하는 것이 필요합니다.', 'category': 'assist_answer'}, {'content': '고막염은 귀의 중이염을 치료하기 위해 사용되는 다양한 약물과 방법이 있습니다. 경구용 진통제는 이부프로펜과 파라세타몰(아세트아미노펜)을 사용하며, 통증을 완화시키고 염증을 감소시킵니다. 이들 약물은 중이염의 진행을 제한하는데 도움이 될 수 있습니다. 국소용 항생제는 염증과 통증을 감소시키는데 사용됩니다. 항생제는 통증을 일으키는 세균에 대항하는 항균 및 항생제 활성을 갖고 있습니다. 고막염 치료에는 아목시실린(Amoxicillin)과 세프트리악손(Seftrifyacin)이 주로 사용됩니다. 아목시실린은 중이의 염증을 감소시키고 감염을 제거하는 역할을 합니다. 세프트리악손은 통증을 완화하는 데 사용되며, 세균 번식을 억제합니다. 아편 유사제는 신경이 과민한 상태에서 통증을 완화하고 귀에 열이 있는 환자에게 사용됩니다. 또한, 파라세타몰(Paracetamol)과 벤조카인(Benzocaine) 점액은 염증을 감소시키고 귀에 물이 들어있는 상태를 치료하는데 사용됩니다. 약물 치료는 개개인의 상황에 따라 다양하게 사용될 수 있습니다. 고막염의 증상이 있는 경우 즉시 의사에게 상담하여 적절한 약물 치료를 시작하는 것이 중요합니다. 의사의 조언을 따르면 염증을 감소시키고 통증을 완화할 수 있습니다.', 'category': 'assist_answer'}, {'content': '고막염을 조기에 발견하기 위해 어떤 검진을 권장하시나요?', 'category': 'assist_question'}, {'content': '고막염을 확인하기 위해 어떤 검진을 권장하나요?', 'category': 'assist_question'}, {'content': '고막염을 의심할 때 어떤 의사를 찾아가야 할까요?', 'category': 'assist_question'}, {'content': '고막염의 초기 증상을 알아내기 위해 어떤 검진을 받아야 하는지 자세한 설명을 듣고 싶어요.', 'category': 'assist_question'}, {'content': '고막염을 의심할 때 어떤 종류의 병원으로 가야 정확한 검진을 받을 수 있을까요?', 'category': 'assist_question'}, {'content': 'HIV 감염 검사는 매우 중요한 절차입니다. HIV 감염 검사는 조기에 HIV 바이러스 감염 여부를 확인하고 적절한 치료를 받을 수 있게 도와줍니다. HIV 감염 검사에는 2가지 주요한 요소가 포함됩니다. 첫째, HIV 항체 검사는 HIV에 감염된 지 여부를 확인하는 데 사용됩니다. 두 번째, HIV 항체/항원 결합 검사는 HIV에 감염되었을 때 항체와 항원이 존재하는지를 파악하는 검사입니다. HIV 감염 검사는 HIV 바이러스에 대한 조기 진단과 조기 치료를 가능하게 해줍니다. 이 검사들은 환자의 건강 상태를 평가하고 적절한 치료 계획을 세울 수 있도록 도와줍니다.', 'category': 'internal_answer'}, {'content': 'HIV 감염 건강검진을 통해 HIV 항체 검사와 항원 검사를 받을 수 있습니다. 이 두 검사는 HIV 감염 여부를 빠르게 확인하고 치료에 필요한 정보를 제공하기 위해 사용됩니다. HIV 항체 검사는 HIV에 대한 항체를 감지하여 감염 여부를 확인하는 검사입니다. 혈액 샘플이나 치약 테스트, 홈 테스트 형태로 제공될 수 있습니다. 혈액 검사는 면역 세포의 활성을 확인하여 HIV에 대한 면역 상태를 확인할 수 있는 검사입니다. 항원 검사는 HIV와 결합할 수 있는 항원의 존재 여부를 확인하는 검사입니다. 이러한 검사는 HIV 감염 여부를 빠르게 확인하고 정확한 치료를 위해 중요합니다. HIV 항체 검사와 항원 검사는 HIV 감염 여부를 빠르게 확인하고 치료에 필요한 정보를 제공하여 감염을 예방하는 데에 큰 역할을 합니다.', 'category': 'internal_answer'}, {'content': 'HIV 감염 건강검진은 HIV에 감염된 사람들이 조기에 식별하고 적절한 치료를 받을 수 있도록 지원하는 중요한 절차입니다. HIV 감염 여부를 검사하기 위해 혈액 채취와 감염 여부 확인을 위한 검사가 이루어집니다. HIV 감염의 예방과 조기 발견을 위해서는 정기적인 혈액 검사가 필요합니다. 정기적인 혈액 검사를 통해 혈액 내의 HIV-1 바이러스 농도를 측정하고, 양성 결과가 나온 경우에는 적절한 치료 방법을 결정할 수 있습니다. 양성 결과의 경우에도, 더 정확한 진단을 위해 추가 검사나 상담이 이루어져야 합니다. HIV 감염 예방을 위해서는 HIV 감염자와의 직접적인 접촉을 피하는 것이 중요합니다.', 'category': 'internal_answer'}, {'content': 'HIV 감염 진단은 HIV 감염이 의심될 때 HIV 감염을 감지하고 조치를 취하기 위해 중요한 과정입니다. 1. 면역세포 검사: 면역세포를 검사하여 HIV 감염 여부를 확인하는 것이 일반적입니다. 면역세포는 면역 기능을 담당하므로 면역세포가 감염된 경우 면역 기능이 약해져 감염이 발생할 가능성이 높아집니다. 면역세포 검사는 감염의 가능성을 파악하고 적절한 예방 및 치료 방법을 결정하는 데 도움을 줄 수 있습니다. 2. 감염 원인 확인: 면역세포 검사로 HIV 감염 여부를 확인하면 감염의 원인을 확인할 수 있습니다. HIV에 감염되는 경우 특정 면역세포가 활성화되어 감염이 발생할 수 있습니다. 이를 통해 예방 및 치료를 위한 적절한 조치를 취할 수 있습니다. 3. HIV 음성 검사: HIV 감염 여부를 확인하기 위해 의사는 HIV 음성 검사를 시행할 수 있습니다. 음성 결과는 감염이 아니라고 확인하는 것이며, 추가 검사와 상담을 통해 적절한 조치를 취할 수 있습니다. 4. 재검사 및 상담: 면역세포 검사와 음성 검사 결과가 나오면 추가적인 검사와 상담을 통해 감염 여부를 확인하고 치료 및 관리에 필요한 조치를 취할 수 있습니다. HIV 감염 진단은 감염 의심 시 정확한 검사와 음성 검사를 통해 HIV 감염을 확인하는 것이 중요합니다. 이를 통해 적절한 치료와 관리를 위한 조치를 취하여 건강을 보호하고 감염자와의 감염을 예방할 수 있습니다.', 'category': 'internal_answer'}, {'content': 'HIV 감염 건강검진은 HIV에 감염되었는지 여부를 확인하고 예방 및 치료를 위해 수행되는 중요한 절차입니다. HIV 감염 건강검진은 주로 혈액 샘플을 사용하여 검사가 진행되거나 치약 테스트 또는 홈 테스트 형태로 제공됩니다. 혈액 샘플을 사용하여 HIV 감염 여부를 확인하는 경우나 치약 테스트 또는 홈 테스트로 HIV 감염 여부를 확인하는 경우도 있습니다. HIV 감염 진단은 익명성과 비밀성을 보장하며, 검사 결과는 음성 결과가 나올 수도 있고 양성 결과가 나올 수도 있습니다. 양성 결과의 경우, 추가 검사와 상담을 통해 진단이 확정되면 적절한 치료 계획을 수립할 수 있습니다. HIV 감염 건강검진은 HIV 감염 여부를 신속하게 확인하고 효과적인 치료를 제공하기 위해 중요한 단계입니다. 정기적인 검사를 통해 HIV 감염 예방을 위한 확실한 해결책을 찾을 수 있습니다.', 'category': 'internal_answer'}, {'content': 'HIV 감염을 의심하고 있는데, 어떤 곳에서 검진을 받아야 할까요?', 'category': 'internal_question'}, {'content': '성 접촉 이후 HIV 감염으로 인한 증상이 어떻게 나타나는지 알고 싶어요.', 'category': 'internal_question'}, {'content': 'HIV 감염을 진단하기 위해 사용되는 주요 검사 방법은 무엇인가요?', 'category': 'internal_question'}, {'content': 'HIV 감염을 의심할 때 어떤 검사를 통해 진단을 받아야 할까요?', 'category': 'internal_question'}, {'content': 'HIV 감염 검사는 백혈구 수치 감소로 인해 권장되는 검사인가요?', 'category': 'internal_question'}]\n"
     ]
    }
   ],
   "source": [
    "print(category_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "992ef39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5569ab8e824881978cda58071eebad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 임베딩 및 DB 구축 (벡터DB 역할)\n",
    "texts = [d['content'] for d in category_data]\n",
    "categories = [d['category'] for d in category_data]\n",
    "embeddings = embedder.encode(texts, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e539fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# 경로 설정\n",
    "save_path = \"vector_db/category\"\n",
    "\n",
    "import os\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 저장\n",
    "with open(os.path.join(save_path, \"texts.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(texts, f)\n",
    "\n",
    "with open(os.path.join(save_path, \"categories.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(categories, f)\n",
    "\n",
    "torch.save(embeddings, os.path.join(save_path, \"embeddings.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1ab1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "with open(os.path.join(save_path, \"texts.pkl\"), \"rb\") as f:\n",
    "    texts = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(save_path, \"categories.pkl\"), \"rb\") as f:\n",
    "    categories = pickle.load(f)\n",
    "\n",
    "embeddings = torch.load(os.path.join(save_path, \"embeddings.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbc605da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_fassis(input_text, top_k=5):\n",
    "    # 입력 텍스트 임베딩\n",
    "    input_embedding = embedder.encode([input_text], convert_to_tensor=True)\n",
    "\n",
    "    # 유사도 계산\n",
    "    sims = cosine_similarity(input_embedding.cpu(), embeddings.cpu())[0]\n",
    "\n",
    "    # Top-K 유사도 추출\n",
    "    top_k_idx = np.argsort(sims)[-top_k:][::-1]\n",
    "    top_results = [(texts[i], categories[i], float(sims[i])) for i in top_k_idx]\n",
    "\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63459b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "\n",
    "def ask_llm_for_final_category(input_text, retrieved_examples):\n",
    "    fewshot = \"\"\n",
    "    for i, (ex, cat, score) in enumerate(retrieved_examples):\n",
    "        fewshot += f\"예시 {i+1}:\\n텍스트: \\\"{ex}\\\"\\n카테고리: {cat}\\n\\n\"\n",
    "\n",
    "    valid_categories = [\n",
    "        \"medicine\",\n",
    "        \"treatment\",\n",
    "        \"assist_answer\",\n",
    "        \"assist_question\",\n",
    "        \"internal_answer\",\n",
    "        \"internal_question\"\n",
    "    ]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "당신은 텍스트를 아래 6가지 카테고리 중 하나로만 분류해야 하는 전문가입니다.\n",
    "\n",
    "선택 가능한 카테고리:\n",
    "- medicine\n",
    "- treatment\n",
    "- assist_answer\n",
    "- assist_question\n",
    "- internal_answer\n",
    "- internal_question\n",
    "\n",
    "아래는 분류된 예시들입니다:\n",
    "{fewshot}\n",
    "\n",
    "이제 입력된 텍스트를 위 카테고리 중 **하나만** 선택하여 분류하세요.\n",
    "카테고리 이름만 출력하세요. 다른 설명 없이 정확히 하나의 카테고리명만 출력해야 합니다.\n",
    "\n",
    "입력 텍스트: \"{input_text}\"\n",
    "\n",
    "정답 카테고리:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d4ead57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 카테고리: assist_question\n"
     ]
    }
   ],
   "source": [
    "input_text = \"소화가 안될때 무슨약을 먹어야하지?\"\n",
    "\n",
    "# 1. FASSIS 유사도 기반 top-5 후보 추출\n",
    "top_k = classify_with_fassis(input_text, top_k=5)\n",
    "\n",
    "# 2. LLM으로 최종 카테고리 분류\n",
    "final_category = ask_llm_for_final_category(input_text, top_k)\n",
    "\n",
    "print(\"예측된 카테고리:\", final_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf2a585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "medicine: 100%|██████████| 41801/41801 [30:43<00:00, 22.68it/s]  \n",
      "treatment: 100%|██████████| 14164/14164 [04:52<00:00, 48.50it/s]\n",
      "assist_answer: 100%|██████████| 586186/586186 [2:12:59<00:00, 73.46it/s]  \n",
      "assist_question: 100%|██████████| 312321/312321 [55:19<00:00, 94.08it/s]  \n",
      "internal_answer: 100%|██████████| 1380716/1380716 [4:40:48<00:00, 81.95it/s]   \n",
      "internal_question: 100%|██████████| 830810/830810 [2:25:05<00:00, 95.43it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 파일을 all_docs.jsonl로 병합 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 폴더 목록\n",
    "folders = [\n",
    "    (\"medicine\", \"data/row_docs/kwon/medicine/3.개방데이터/1.데이터/Training/01.원천데이터\"),\n",
    "    (\"treatment\", \"data/row_docs/kwon/medical_treatment/09.필수의료_의학지식_데이터/3.개방데이터/1.데이터/Training/01.원천데이터\"),\n",
    "    (\"assist_answer\", \"data/row_docs/kwon/medical_assistance_and_convergence_areas/Training/OnChwon/answer\"),\n",
    "    (\"assist_question\", \"data/row_docs/kwon/medical_assistance_and_convergence_areas/Training/OnChwon/question\"),\n",
    "    (\"internal_answer\", \"data/row_docs/kwon/internal_medicine_and_surgery/Training/OnChwon/answer\"),\n",
    "    (\"internal_question\", \"data/row_docs/kwon/internal_medicine_and_surgery/Training/OnChwon/question\"),\n",
    "]\n",
    "\n",
    "# 2. 파일 병합\n",
    "out_fp = open(\"all_docs.jsonl\", \"w\", encoding=\"utf-8\")\n",
    "for category, folder in folders:\n",
    "    json_files = list(Path(folder).rglob(\"*.json\"))\n",
    "    for json_file in tqdm(json_files, desc=f\"{category}\"):\n",
    "        try:\n",
    "            raw_data = json_file.read_bytes()\n",
    "            encoding = chardet.detect(raw_data)['encoding'] or 'utf-8'\n",
    "            data = json.loads(raw_data.decode(encoding))\n",
    "            data[\"_category\"] = category\n",
    "            out_fp.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"[오류] {json_file}: {e}\")\n",
    "out_fp.close()\n",
    "print(\"✅ 모든 파일을 all_docs.jsonl로 병합 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "embedder = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "texts = []\n",
    "categories = []\n",
    "with open(\"all_docs.jsonl\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"JSONL 임베딩\"):\n",
    "        data = json.loads(line)\n",
    "        # content/question/answer 등 가공\n",
    "        if 'content' in data:\n",
    "            text = data['content']\n",
    "        elif 'question' in data:\n",
    "            text = data['question']\n",
    "        elif 'answer' in data:\n",
    "            ans = data['answer']\n",
    "            if isinstance(ans, dict):\n",
    "                text = ' '.join([ans.get(k, '') for k in ['intro', 'body', 'conclusion']])\n",
    "            else:\n",
    "                text = str(ans)\n",
    "        else:\n",
    "            text = str(data)\n",
    "        texts.append(text.strip())\n",
    "        categories.append(data.get('_category', 'unknown'))\n",
    "\n",
    "# 배치 임베딩\n",
    "embeddings = embedder.encode(texts, batch_size=128, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n",
    "# 저장\n",
    "import pickle\n",
    "save_path = \"vector_db/category\"\n",
    "import os\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "with open(f\"{save_path}/texts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(texts, f)\n",
    "with open(f\"{save_path}/categories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(categories, f)\n",
    "torch.save(embeddings, f\"{save_path}/embeddings.pt\")\n",
    "print(\"✅ 임베딩/카테고리 저장 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
