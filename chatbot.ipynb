{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9466cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.43-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ldgo9\\miniconda3\\envs\\chatbot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.2-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain-openai)\n",
      "  Downloading openai-1.82.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.68.2->langchain-openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ldgo9\\miniconda3\\envs\\chatbot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ldgo9\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 23.4 MB/s eta 0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.43-py3-none-any.whl (361 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl (134 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 26.9 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 23.7 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n",
      "Downloading openai-1.82.1-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 720.5/720.5 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.0/894.0 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading greenlet-3.2.2-cp310-cp310-win_amd64.whl (294 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, pydantic-core, packaging, orjson, jsonpointer, jiter, idna, h11, greenlet, distro, charset-normalizer, certifi, async-timeout, annotated-types, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, httpx, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "\n",
      "   - --------------------------------------  1/37 [urllib3]\n",
      "   - --------------------------------------  1/37 [urllib3]\n",
      "   --- ------------------------------------  3/37 [tqdm]\n",
      "   ---- -----------------------------------  4/37 [tenacity]\n",
      "   ------ ---------------------------------  6/37 [regex]\n",
      "   ------- --------------------------------  7/37 [PyYAML]\n",
      "   -------- -------------------------------  8/37 [python-dotenv]\n",
      "   --------- ------------------------------  9/37 [pydantic-core]\n",
      "  Attempting uninstall: packaging\n",
      "   --------- ------------------------------  9/37 [pydantic-core]\n",
      "    Found existing installation: packaging 25.0\n",
      "   --------- ------------------------------  9/37 [pydantic-core]\n",
      "    Uninstalling packaging-25.0:\n",
      "   --------- ------------------------------  9/37 [pydantic-core]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   --------- ------------------------------  9/37 [pydantic-core]\n",
      "   ---------- ----------------------------- 10/37 [packaging]\n",
      "   -------------- ------------------------- 13/37 [jiter]\n",
      "   --------------- ------------------------ 14/37 [idna]\n",
      "   ----------------- ---------------------- 16/37 [greenlet]\n",
      "   ----------------- ---------------------- 16/37 [greenlet]\n",
      "   ------------------- -------------------- 18/37 [charset-normalizer]\n",
      "   ---------------------- ----------------- 21/37 [annotated-types]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 22/37 [SQLAlchemy]\n",
      "   ------------------------ --------------- 23/37 [requests]\n",
      "   ------------------------- -------------- 24/37 [pydantic]\n",
      "   ------------------------- -------------- 24/37 [pydantic]\n",
      "   ------------------------- -------------- 24/37 [pydantic]\n",
      "   ------------------------- -------------- 24/37 [pydantic]\n",
      "   ------------------------- -------------- 24/37 [pydantic]\n",
      "   ------------------------- -------------- 24/37 [pydantic]\n",
      "   ---------------------------- ----------- 26/37 [httpcore]\n",
      "   ---------------------------- ----------- 26/37 [httpcore]\n",
      "   ----------------------------- ---------- 27/37 [anyio]\n",
      "   ----------------------------- ---------- 27/37 [anyio]\n",
      "   ------------------------------- -------- 29/37 [requests-toolbelt]\n",
      "   -------------------------------- ------- 30/37 [httpx]\n",
      "   -------------------------------- ------- 30/37 [httpx]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   --------------------------------- ------ 31/37 [openai]\n",
      "   ---------------------------------- ----- 32/37 [langsmith]\n",
      "   ---------------------------------- ----- 32/37 [langsmith]\n",
      "   ---------------------------------- ----- 32/37 [langsmith]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ----------------------------------- ---- 33/37 [langchain-core]\n",
      "   ------------------------------------ --- 34/37 [langchain-text-splitters]\n",
      "   ------------------------------------- -- 35/37 [langchain-openai]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   -------------------------------------- - 36/37 [langchain]\n",
      "   ---------------------------------------- 37/37 [langchain]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 certifi-2025.4.26 charset-normalizer-3.4.2 distro-1.9.0 greenlet-3.2.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-core-0.3.63 langchain-openai-0.3.18 langchain-text-splitters-0.3.8 langsmith-0.3.43 openai-1.82.1 orjson-3.10.18 packaging-24.2 pydantic-2.11.5 pydantic-core-2.33.2 python-dotenv-1.1.0 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-inspection-0.4.1 urllib3-2.4.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ec925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d909710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a8a252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# ✅ 세션 히스토리 저장소\n",
    "# -------------------------------\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# ✅ 기본 구성 요소\n",
    "# -------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 유능한 한국어 챗봇입니다. 사용자 질문에 친절하고 자세히 응답해주세요.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 세션 기반 챗봇\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1b5f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[test_user] 챗봇 응답:\n",
      " 안녕하세요! 저는 여러분의 질문에 답하고, 다양한 정보를 제공하기 위해 만들어진 AI 챗봇입니다. 한국어로 소통하며, 여러분이 궁금한 점이나 필요한 정보에 대해 친절하게 도와드릴 수 있습니다. 어떤 질문이든지 편하게 해주세요!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# ✅ 테스트 실행\n",
    "# -------------------------------\n",
    "response = chatbot.invoke(\n",
    "    {\"input\": \"안녕하세요. 자기소개 해주세요.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test_user\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n[test_user] 챗봇 응답:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd0d6cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[test_user] 챗봇 응답:\n",
      " 당신의 전 질문은 \"내 전 질문이 뭐지?\"입니다. 이 질문에 대해 답변을 드리고 있습니다. 더 궁금한 점이나 다른 질문이 있으시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "response = chatbot.invoke(\n",
    "    {\"input\": \"내 전 질문이 뭐지?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test_user\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n[test_user] 챗봇 응답:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "810c0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색된 의학지싟을 넣을 프롬프트 작성\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 유능한 한국어 챗봇입니다. 사용자 질문에 친절하고, 반드시 제공된 문서 내용을 기반으로 답변해주세요.\"),\n",
    "    (\"system\", \"문서 내용:\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6c3e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 내용을 임시로 문자열로 넣기 (파일 로딩 예제는 아래에 있음)\n",
    "doc_content = \"나는 의학지식인데 의학지식테스트야 앞으로 해당 전용 llm의 응답을 넣어서 너가 대답하게 될거야\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aa57434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LLM & 파서 & 체인 구성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc64bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[doc_user] 챗봇 응답:\n",
      " 저는 의학 지식에 기반한 챗봇입니다. 의학 관련 질문에 대한 정보를 제공하고, 여러분의 궁금증을 해결하는 데 도움을 드립니다. 어떤 질문이든지 해주세요!\n"
     ]
    }
   ],
   "source": [
    "chatbot = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 6. 질문 수행(문서 유사도도 판단해야될듯 streamlit 질문입력 -> 카테고리 분석(문서유사도0.5이상만 카테고리 분류))\n",
    "# (문서 유사도 0.5미만일시 context안넣고 바로 답변)\n",
    "# (문서 유사도 0.5이상일시 해당문서 퓨샷하여 카테고리분류)->분류된 카테고리에 맵핑된 llm에 질문 전달(프록시패턴으로 라우팅하기)->해당응답 context에 담아 답변하게 하기\n",
    "# (우리플젝 일단끝)\n",
    "# (내일 코드 분리하고 프록시패턴으로 해당 카테고리에 질문 응답 추상화하기)\n",
    "# (streamlit 까지 작업 꼭하기)\n",
    "response = chatbot.invoke(\n",
    "    {\"input\": \"너는 뭐지?\", \"context\": doc_content},\n",
    "    config={\"configurable\": {\"session_id\": \"doc_user\"}}\n",
    ")\n",
    "\n",
    "print(\"\\n[doc_user] 챗봇 응답:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
